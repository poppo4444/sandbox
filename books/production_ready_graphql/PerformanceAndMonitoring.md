## Performance & Monitoring

APIのパフォーマンスは重要ですが、GraphQLでは以下のような多くの点で少し複雑になることがあります：

• 様々なリクエストのバリエーションが非常に多いため、特定のクエリを最適化することが難しくなります。
• リゾルバのパターンにより、フィールドがキャッシュしたり、事前に作業を行ったりするのが困難になります。
• GraphQLの実行は時としてブラックボックスのように見えることがあります。

これらはGraphQLサーバーを構築する際のトレードオフですが、それは解決策がないという意味ではありません。この章では、GraphQLサーバーがパフォーマンスに優れているかどうかを判断する方法や、効率的なデータ読み込みとキャッシングの方法について詳しく説明します。

### Monitoring

APIのパフォーマンスを向上させることは無意味です、もしパフォーマンスの改善を測定したり、APIのパフォーマンスに問題があることを検出できなければ。

エンドポイントベースのHTTP APIに慣れている場合、以前に成功したパフォーマンス監視を行っていたかもしれません。例えば、APIのパフォーマンスを監視する最も基本的な方法の一つは、応答時間を測定することです。以下のようなダッシュボードがあるかもしれません。

画像

このようにAPIを監視することで、問題を抱えているAPIのサブセットをすばやく発見することができます。例えば、上記の例では、POST /postsエンドポイントで何か問題が発生しているようです。したがって、私たちの最初の直感は、同様の方法でGraphQL APIにアプローチすることかもしれません：

画像

残念ながら、GraphQLエンドポイントの応答時間を測定すると、GraphQL APIの状態についてほとんど情報が得られないことがすぐにわかります。なぜそうなるのか、極めて単純化された例を見てみましょう。あなたが主に以下のようなシンプルなクエリを処理するGraphQL APIを管理していると想像してみてください。

```graphql
query {
 viewer {
    name
    bestFriend {
      name
    }
  }
}
```

あなたのAPIに新しいアプリケーションが登録され、より複雑な要求をするようになりました：

```graphql
query {
 viewer {
    friends(first: 1000) {
      bestFriend {
        name
        favoriteCities(first: 100) {
          name
          population
        }
      }
    }
  }
}
```

クエリのドキュメントサイズは同じに見えますが、新しいクエリでは実際には100,000以上のオブジェクトを要求しており、最初のクエリでは1つだけを要求しています。もし、このGraphQLエンドポイントの応答時間を監視していて、新しいクライアントがこれらのクエリを十分に送信すると、/graphqlの応答時間が上昇することがわかるでしょう、おそらくかなり多く。

これは問題ですか？全く問題ありません、なぜなら、返すレスポンスが少し遅くなっているだけで、単純により複雑なクエリを処理しているからです！私たちが本当に興味があるのは、通常の負荷やユースケースが同じである場合にパフォーマンスが低下したかどうかです。その時に修正が必要になります。

実際には、エンドポイントを監視するのではなく、この場合クエリを監視したいのです。ユーザーが通常200msで実行していたクエリが現在500msかかるかどうかを知りたいのです。もしプライベートAPIのメンテナーで、既知のクライアントとクエリのセットが少ない場合は、そのパフォーマンスを監視することが可能です。

これにより非常に重要な点が明らかになります。クライアントはクエリを行っている人物を特定するための情報を必ず含めるべきです。公開APIでは、認証トークンを使用していればそれが当然となりますが、内部でGraphQLを使用しているチームはしばしばクライアントが誰であるかを全く追跡していません。各呼び出しにクライアントIDとクライアントアプリのバージョンを渡すことを検討すべきです。

クエリと共にこの情報を提供しないクライアントからのクエリに対応しないことも可能です。一般的な方法としては、ヘッダーを通じてこの情報をクライアントに含めることです：

```http
GraphQL-Client-Name: my-app
GraphQL-Client-Version: 15.4.2
```

最後の章で見た「持続クエリ」では、この情報を持続クエリと共に付けることがさらに簡単になります。

しかし、もしあなたがパブリックAPIを管理しているか、または大規模な内部APIを多数のクライアントとクエリで管理している場合、クエリの高度なカーディナリティ（異なり数）のため、これを実現するのは簡単ではないかもしれません。この場合、他の解決策を見つける必要があります。

#### Per-Field Monitoring & Tracing

私はGraphQLクエリのライフサイクルを3つの広範なステップで考えることがよくあります。
• パース & 字句解析
• 検証 & 静的分析
• 実行
問題が発生する箇所は常にクエリの実行だけではないため、これらの各ステップのタイミングを監視することが有用です。複雑なクエリを解析するのに非常に時間がかかるバリデーターの例を数えきれないほど見てきました。また、クエリの計算時間の大部分を占めるパースもあります。多くのGraphQLライブラリでは、カスタムトレーシングロジックを挿入するためのフックを提供しています。

フィールドごとの監視は、より詳細なデータを得る方法です。しかし、この種の監視データを収集する方法によってはコストがかかることもあります。この考え方は、クエリ文字列全体の応答時間を監視するだけでなく、個々のフィールドのパフォーマンスも見ていきます。これにより、全体的なクエリパフォーマンスを見る時よりも、例外的な状況をより良く検出できます。

フィールドとリゾルバの監視は、多くのライブラリが提供するミドルウェアやリゾルバ拡張と共に、お気に入りのアプリケーションパフォーマンス管理ライブラリ/ベンダを使用して達成できることが多いです。例えば、GraphQL-RubyではPrometheusやその他の多くのベンダ/ツールを使ってクエリを容易に計測することができます。既製品が良ければ、Apollo ServerとApollo Engineを一緒に使うことで、非常に簡単にメトリクスとログを取得することができます。
また、GraphQLはトレーシングに最適です。GraphQLクエリの実行を細かいトレースとして視覚化することで、全クエリの全応答時間よりもはるかに多くの情報を得ることができます。多くのGraphQL実装では、OpenTracingのようなトレーシング実装のフックを提供します。

#### GraphQL Response Extensions

遅いクエリをデバッグする際など、クエリ応答内に直接パフォーマンス情報を提供することは非常に有用です。GraphQLの仕様では、extensionsキーの下に応答の一部として追加情報を含めることができます。これはトレーシング情報などのメタデータにとって非常に有用です。Apollo Tracingはトレーシング拡張形式を定義していますが、それが必ずしも公式の標準であるとは限りません。自分自身のトレーシング拡張を作り出すことも可能です。

```json
// An example of the Apollo Tracing extension
{
  "data": <>,
  "errors": <>,
  "extensions": {
    "tracing": {
      "version": 1,
      "startTime": <>,
      "endTime": <>,
      "duration": <>,
      "parsing": {
        "startOffset": <>,
        "duration": <>,
      },
      "validation": {
        "startOffset": <>,
        "duration": <>,
      },
      "execution": {
        "resolvers": [
          {
            "path": [<>, ...],
            "parentType": <>,
            "fieldName": <>,
            "returnType": <>,
            "startOffset": <>,
            "duration": <>,
          },
        ...
        ]
      }
    }
  }
}
```

特に重要なことは、リゾルバ毎のタイミングだけでなく、リゾルバが行う全ての外部呼び出しのタイミングもエンコードすることです。リゾルバ自体がCPUの観点から遅いということは非常に稀です。パフォーマンス問題の大部分は、リゾルバがキャッシュ、データベース、または外部サービスへの呼び出しを行うことに由来します。これらはこのようなトレースに含めるのが非常に有用です。ただし、このトレースを全てのレスポンスで返すことは希です。なぜなら、クライアントが全てこの情報を使うことを期待している場合に限ります。それはレスポンスに多くのバイト数を追加することが多いからです。少なくともそれが圧縮されていることを確認すべきです。もし公開APIを管理している場合、セキュリティのためにこのような詳細なトレースを公開したくないかもしれません。

#### Slow Query Log

スロークエリログは、データベース実装から派生したアイデアです。このアイデアはシンプルで、クエリが遅すぎるとみなされる閾値を設定します。その閾値を超える任意のクエリはログに記録されます。これは既知のクエリセットを取り扱ったり、パブリックまたは十分に大きなクライアントとクエリのセットを取り扱ったりする場合に最も有用です。そうした場合、私たちは本章の冒頭で述べた同じ問題に直面します：スロークエリは問題を引き起こすのか、それとも単に大規模なクエリであるために遅いのか？それでも、スロークエリログは高価なクエリを早期に察知して対処するために、シンプルかつ効果的なツールになることがあります。

#### Tracking Queries over Time

パフォーマンスの観点から言えば、我々が本当に関心を持っているのが回帰（遅延）でしょう。過去数時間、一日、一週間で遅くなったクエリは何かありますか？負担が許せば、時系列データベースやデータウェアハウスのようなもので時間をかけてすべての単一クエリを追跡することは非常に有用です。自分でビルドしたくない場合、Apollo Platformなどの製品が同様の機能を提供します。空白、引数、フィールドの順序によってクエリストリングが大幅に変化するため、クエリのハッシュまたは署名を計算する必要がよくあります。そうすると、平文のクエリストリングを追跡する代わりに、特定のクエリハッシュのパフォーマンスを追跡できます。GitHubでは、クエリストリングと提供される変数の両方のハッシュを計算します。その後、特定のクエリストリング+変数ペアの回帰を追跡できるようになり、先に説明した監視問題（250件のアイテムをロードするのは、1件をロードするよりも固有の遅さがある）を避けられます。

### The N+1 Problem and the Dataloader Pattern

クライアント表現を動的に生成できる非常に強力な概念であるにも関わらず、"resolver" パターン（ほとんどのGraphQL実装がクエリを実行するために使用する関数）は、単純に使用したときに予期しない問題を引き起こすことがあります。
これはデータロードのケースでそうです。問題は、リゾルバが自己完結型の世界（事実、他のものと並行して実行されることさえあります）に生きており、データを必要とするリゾルバは、それが以前にロードされたデータなのか、後からロードされるデータなのかを知らないということです。例えば、特定のユーザーをロードする必要がある三つのリゾルバは、同じSQLクエリを最終的に生成する可能性があります：

画像

ほとんどのサーバーは、実際にはクエリを逐次的に解決します。これはつまり、一つのフィールドを一つずつ処理します。現在のユーザーの名前と年齢、すべての友人、そして各友人のベストフレンドをロードする典型的なクエリの実行を見てみましょう。

画像

このGraphQLクエリを外部から見て、私たちはどのように必要なデータをロードしたいかを想像することができます。実際、エンドポイントベースのAPIを取り扱っていた場合、すなわち全ペイロードのシリアライゼーションロジックがしばしば一箇所にまとまっているか、少なくとも共有コンテキストで実行される場合、私たちはこれをどのように行うかを知っています。ここでは、現在のユーザーをロードし、結合テーブルから最初の3人の友人をロードし、それらの友人をIDを使用して一度にロードします。最後に、各ユーザーからbest_friend_idを取り出し、それらすべてをロードします。リゾルバグラフを見て、以下の4つのクエリを持つことになります：

画像

上記で見たように、この目標を達成するのは、リゾルバの概念を用いると難しいです。friends(first: 3)のリゾルバが、それぞれのベストフレンドを事前にロードする必要があることをどのようにして知るのでしょうか？これはbestFriendフィールドの責任です！bestFriendのロードがbestFriendリゾルバにて一箇所に集められることは素晴らしいことですが、このクエリを単純に実行すると以下のような結果になります：

画像

見ての通り、典型的なGraphQLの実行では、ここで4つのクエリの代わりに6つのクエリを生成する可能性が高いです。50人分のユーザーを要求すれば、53クエリが発生しますが、他の解決策ではまだ4回のSQL呼び出しで済むでしょう！これは明らかに受け入れられない状態であり、データセットが大きくなると、さらにその種類のクエリがGraphQL APIに対して実行されると、すぐに問題が発生します。問題がわかったところで、これに対して何ができるでしょうか？問題を見る方法は複数あります。一つ目のアプローチは、子供のリゾルバが自分のデータの小部分をロードするのを待つのではなく、データを事前にロードする方法がないかを自分自身に尋ねることです。この場合、friendsリゾルバで「先読み」を行い、各友人のベストフレンドをロードする必要があることを確認することができます。それから、それらのデータを事前にロードし、各bestFriendリゾルバはこの事前ロードされたデータの一部を使用するだけでよいかもしれません。
しかし、この解決策は最も人気のあるものではありません。そしてそれは理解できます。GraphQLサーバーは通常、クライアントが好きな表現でデータを問い合わせることを許します。これは、私たちのローディングシステムがクエリのあらゆるシナリオに対応する必要があることを意味します。そしてそのシナリオはクエリの遠くに細分化されて現れます。間違いなくこれは可能ですが、今まで見てきた限りでは、ほとんどの解決策はかなり単純であり、非常に複雑なデータローディングシナリオで最終的に破綻します。それどころか、現在より一般的なアプローチは、“DataLoader”と通称されているものです。これはGraphQLのこのパターンの最初の実装がJavaScriptライブラリとしてDataLoaderとしてリリースされたためです。

#### Lazy Loading

DataLoaderのアイデアは、私たちがさきほど話した「先読み」ソリューションとはちょっと逆です。データを貪欲にロードする代わりに、DataLoaderスタイルのローディングパターンは積極的にデータをロードしないことを目指しています。それでは詳しく説明しましょう。

まず理解するべき最初の原則は、DataLoaderのアプローチを利用する時、私たちはリゾルバーに対して非同期型のアプローチを取るということです。これは、リゾルバーがもはや常に値を返すわけではなく、ある種の「不完全な結果」を返せるようになることを意味します。この例では、最も一般的に使用される「不完全な結果」オブジェクト、つまり、プロミスについて説明します。

画像

見ての通り、標準の実行戦略では深さ優先探索のアプローチでクエリを実行し、同じレベルの他のフィールドよりも先に子フィールドを解決しますが、ここでは別のアプローチを取っています。リゾルバーがデータをフェッチしたい場合、すぐに取得するのではなく、将来的にはデータがあることを実行者に知らせる一方、現状ではクエリツリーの同じレベルの次のリゾルバーに進んで欲しいと要求します。

画像

この方法がどのように最終的に動作するかを理解するための次のステップは、ローダーの概念を紹介することです。ローダーはシンプルなアイディアであり、その実装が複雑であるかもしれません。基本的なアイディアは、個々のリゾルバーがデータニーズを持っている際、それがストレートにデータストアに行く代わりにローダーを通過するというものです。ローダーの役割は、個々のリゾルバーからオブジェクトをフェッチするために必要な識別子を集め、このデータをより効率的にバッチロードすることです。

ローダーの典型的な抽象化は、主に二つのメソッドを持つクラスまたはオブジェクトです:

- #loadは呼び出し元が興味を持っているデータのロードキーを引数に取り、最終的には呼び出し元が求めたデータで満たされるプロミスを返します。このメソッドはリゾルバー内部で使用されます。
- #perform (batchFunction)は load関数呼び出しで追加されたすべての累積キーを取り、最も効率的な方法でデータをロードします。これは通常、私たちが定義するか、私たちが提供したバッチ関数を呼び出す。

```ruby
class Loader {
  load(key) {
    // Adds the key to an eventual batch and returns a promise
  }
  perform(keys) {
    // Receives all keys that were asked to be loaded
    // Loads them all as a batch
    // Fulfills every resolver promise with the
    // data they've asked for
  }
}
```

ここでは、DataloaderパッケージとGraphQL-Jsを使用した実際の例を示します:

```js
// Create a loader that can fetch multiple users
// in a single batch
const userLoader = new DataLoader(ids => getUsers(ids));
const UserType = new GraphQLObjectType({
  name: 'User',
  fields: () => ({
    name: { type: GraphQLString },
    bestFriend: {
      type: UserType,
      // The bestFriend resolver now returns a Promise
      // instead of loading the user right away.
    resolve: user => userLoader.load(user.bestFriendID)
    },
  })
})
```

通常、最初は理解しづらいことの1つは、そのパフォーマンスまたはバッチ関数が実行中にいつ呼び出されるかです。私たちはリゾルバーが個別にデータをロードしないことを知っていますが、これらのプロミスはいつ果たされるのでしょうか？ GraphQL実行エンジンはこれをどのように処理するのでしょうか？ 実際のところ、実装や言語によって大幅に異なります。

例えば、Node.jsには非同期プリミティブがあり、このパターンをうまく機能させます。これがDataLoaderが process.nextTick を使用してキーセットをバッチロードする理由です。 DataLoaderはNode.jsのキューシステムを使用してすべてのプロミスがエンキューされるのを待ち、その後バッチ関数を実行します。 この仕組みについて詳しく知りたい場合、Lee Byron氏による素晴らしいビデオ解説があります。特にenqueuePostPromiseJobについての部分を見ることを強く推奨します。

他の言語では異なる方法を取ります。たとえば、GraphQL-Rubyには特定の「遅延実行者」が存在し、クエリの単一レベルで全てのフィールドリゾルバー関数を解決し始め、それ以上プロミスを解決せずに先に進めなくなった場合、ローダー上のバッチ関数を呼び出します。そして、プロミスが果たされると実行を続行します。

画像

あなたがDataLoaderを実装することを考えているなら、JavaScriptの実装リポジトリにはこのパターンの言語固有の実装が多数記載されており、それらから選ぶことができます。

#### Lazy Loading Drawbacks

GraphQLサーバーのパフォーマンスに関して、遅延ローディングは非常に重要な部分であることがよくありますが、いくつかの欠点もあります。

モニタリングが少し難しくなります。実行はもはや個々のリゾルバーのタイミングだけではありません。
以前と同様に明確な実行メンタルモデルがなくなり、パフォーマンスの問題のデバッグが難しくなります。
独立したフィールドのパフォーマンスが偽りである可能性があります。例えば、何千人ものユーザーを読み込むためのキューに単純に追加するフィールドを想像してみてください。そのフィールドのパフォーマンスを監視した場合、非常に早く解決することがわかります。実際には、全ての作業をローダーに委ねています。そのローダーを別途監視する必要があります。
全てが非同期になります！ JavaScriptと一緒に働くのに慣れているならそれは良いかもしれませんが、プロミス/フューチャーに対するサポートが貧弱な言語で働いている場合、それはかなり扱いづらいかもしれません。

### Caching

GraphQLが良いアイデアかどうかについての議論を追ってきたら、「GraphQLはキャッシュを壊す」や「GraphQLはキャッシュ可能ではない」というようなことを聞いたことがあるかもしれません。そうでなければ、GraphQL APIを構築する興味を示し始めた時に同じようなことを聞くことになるでしょう。私は一部の企業がこの問題に対して明確な答えを持たずにGraphQLの使用を恐れて始めるのを見てきました。キャッシングとGraphQLの世界に深入りする前に、これらの一般的な懸念について説明し、それらがどこから来ているのかを理解することが良いでしょう。
「GraphQLはキャッシングを壊す」というようなコメントは、キャッシングとGraphQLについて適切な議論を行うために必要なニュアンスを欠いています。どの種類のキャッシングですか？ クライアント側？ サーバー側？ HTTPキャッシング？ アプリケーションサイドのキャッシュ？ GraphQLのキャッシングに関する制限をより良く理解し、適切な議論を行うためには、特定の微妙な点を考慮に入れる必要があります。

#### GraphQL breaks server-side caching?

GraphQLについて話すときによく投げかけられることです。最初に理解するべきことは、「サーバーサイドのキャッシュ」は既に曖昧であるということです。現時点では、GraphQLが実際に既存のサーバー上の薄い層になり得ること、そしてGraphQLが何らかの形で我々がサーバーサイドでキャッシュすることを防ぐわけではないことを知っています。これをアプリケーションキャッシングとも呼びます。この章の後半部分で、アプリケーションレベルで適用可能ないくつかの概念について詳しく説明します。
ほとんどのGraphQLクライアントやフレームワークには、クライアントサイドのアプリケーションが既に持っているデータを再取得することを避ける、非正規化キャッシュが特徴としてあります。これはUIを楽観的に更新し、コンポーネント全体で一貫したバージョンの世界を保つために使用されます。したがって、私たちは実際にはサーバーとクライアントの両方のレイヤーで物事をキャッシュすることができますが、なぜ私たちはGraphQLが「壊れている」、またはキャッシュを非常に困難にしているとよく耳にするのでしょうか？ ここでさらに微妙な点が出てきます。

#### HTTP Caching


RESTのような特定のAPIスタイルは強力なHTTPセマンティクスを大いに活用していますが、GraphQLはそうではない、少なくともデフォルトではありません。GraphQLがトランスポートに依存しないため、ほとんどのサーバー実装はHTTPを「ダムパイプ」として使用します、つまりそのフル潜能を利用することはありません。これにより、HTTPキャッシングなどの問題が発生します。HTTPキャッシングに関連する重要な部分がいくつかあります。それを理解する前によく考えてみましょう。

まず、HTTPキャッシングに関与する可能性のある多くの異なるキャッシュエンティティがあります。クライアント側のキャッシュ（ブラウザーキャッシュなど）はHTTPキャッシングを使用して、データがまだ新鮮である場合に再取得を回避します。ゲートウェイキャッシュは通常、サーバーと一緒にデプロイされ、情報がキャッシュレベルでまだ最新である場合には、常にリクエストがサーバーにヒットするのを回避します。

HTTPキャッシングについて理解する上で特に重要な2つの概念：新鮮さと検証です。新鮮さでは、サーバーが Cache-Control と Expires HTTP ヘッダーを通じて、リソースが新鮮であると見なすべき時間を送信します。例えば、このCache-Controlヘッダーを返すサーバーは、クライアントに対して、このリソースが少なくとも1時間(3600秒)経つまで再取得する必要はないと伝えています:

```http
Cache-Control: max-age=3600
```

これは、ブラウザのアセットのような、頻繁に変更されないデータにとって非常に優れています。我々が取得したリソースの年齢がこのmax-ageよりも大きくなるたびに、クライアントはキャッシュの値を使用する代わりにリクエストを送信します。しかし、それがサーバー上で実際に変更されたことを意味するわけではありません。

ここで検証が登場します。検証は、クライアントがデータがまだ新鮮であるかどうか確信が持てないときに、再取得を避けるための方法です。これを達成するための一般的なHTTPヘッダーが2つあります。ひとつはLast-Modifiedです。サーバー上のHTTPキャッシュにLast-Modifiedの値があるとき、クライアントはIf-Modified-Sinceを送信して、データが前回取得してから変更されていない場合、それをダウンロードしないようにします。

別の一般的なキャッシュ検証方法はETagの使用です。ETagsは、リソースが変更されるたびに変更される表現に対するサーバー生成の識別子です。これにより、クライアントは自身が持っている「バージョン」を追跡し、クライアントが持っているETagと同じETagを持つ表現を再ダウンロードするのを避けることができます。

新鮮さと検証は、クライアントとゲートウェイキャッシュを制御する強力な方法です。私たちは本当に、GraphQLでHTTPキャッシングの力を利用することはできませんか？

#### GraphQL & HTTP Caching

GraphQLとキャッシングの問題を深く掘り下げると、これらの問題の一部は純粋にHTTPキャッシングに関連していることが分かります。これは重要な区別であり、サーバー側のキャッシングはHTTPゲートウェイキャッシュである場合も、サーバー上のアプリケーション側のキャッシングである場合もあります。

GraphQLとHTTPキャッシングがどのように連携するかに影響を与える最初の要素は、GraphQLクエリを送信するために使用されるHTTP動詞です。誤情報が広まっているため、一部の人々はGraphQLエンドポイントでPOSTを使用するのが唯一の方法だと考えています。HTTPキャッシュはPOSTリクエストをキャッシュしないため、GraphQLはHTTPレベルではキャッシュ可能ではありません。ただし、GETは確かにHTTP経由でGraphQLサーバーにクエリを送信する有効な方法です。つまり、キャッシュできるGraphQLのレスポンスが確実に存在します。

GETで問題となるのはクエリ文字列のサイズです。例えば、ほぼすべてのブラウザーにはこれらに対する異なる制限があります。これが問題となる場合、永続的なクエリが非常に役立ちます。前章で見たように、永続的なクエリはクエリ文字列をクライアントではなくサーバー側に保存することを可能にします。つまり、クライアントは以下のようにクエリを実行できます：

GET /graphql/my_query

永続的なクエリを使った私たちのGraphQLクエリは、基本的には典型的なHTTPエンドポイントです！永続的なクエリについて話すときにカバーしたように、もし私たちがGraphQLクエリを、動的に生成するクライアント固有のサーバーサイド表現として見るならば、各クエリは実際にキャッシュ可能なものです。

次にフレッシュさについて考えてみましょう。サーバーがクライアントに対して、どのくらいの期間クエリが新鮮であると考えられ、いつこのデータを再度要求するべきかを伝えることができるようにしたいです。ここで残念なことに、HTTPのセマンティクスは全体のレスポンス/表現に作用し、GraphQLのクエリを理解したり気にしたりしないため、例えばフィールド毎の新鮮さを行う方法はありません。しかし、全体のクエリに新鮮なヘッダーを追加することは何も阻むものはありません：GraphQLクエリのmax-ageは、クエリ内の最低のmax-ageを持つフィールドに等しいと言うことができます。

検証も同様です。クエリの一部だけを再検証するためにHTTPを使用することはできませんが、Last-Modifiedを最も古いLast-Modified値を持つフィールドの値に設定することができますし、クエリ内でロードされたすべてのデータの組み合わせに基づいてETagを生成することも可能です。

GraphQLのクエリは複数のエンティティを網羅し得る可能性があり、それらがGraphQL側で一つの表現として表現される必要があるため、GraphQLのクエリの無効化は通常非常に多いです。単一のフィールドが無効化されると、クエリ全体が無効化されます、たとえそれがまだ「新鮮」であっても。

これが一部人々にとっては「GraphQLは基本的にキャッシュ不可能」と聞こえるかもしれませんが、実際にはカスタマイズと最適化のトレードオフにすぎません。上記で議論した無効化の問題はGraphQL特有のものではなく、GraphQLと同様に動的でカスタマイズ可能なすべてのAPIが抱えるものです。これは私たちが選択するトレードオフです！

例えば、Web APIの典型的なHTTPエンドポイントを取り上げてみましょう：

GET /user/1

この特定のエンドポイントは特別なクエリパラメータを受け付けず、単にこのURIに関連付けられたユーザーを返します。特に公開APIとして、このエンドポイントは全てのAPIクライアント間で非常にキャッシュ可能です。もっとカスタマイズ可能なバージョンのエンドポイントを考えてみましょう：

GET /user/1?partial=complete
GET /user/1?partial=compact

このAPIは、レスポンスの詳細レベルを変更するために、部分的なクエリパラメータを使用します。さらにカスタマイズ可能なAPIは、序文で見たように以下のようになります：

GET /user/1?fields=name,friends

HTTPエンドポイントのバージョンが多ければ多いほど、キャッシュを希釈します。つまり、fields=nameだけをリクエストする人は、fields=name,friendsをリクエストした誰かがキャッシュを使用できないという意味です。GraphQLにも同じ問題があります。フィールドを削除したり、クエリを何かしら変更したりすると、データセットのスーパーセットやサブセットでキャッシュされたすべてのクエリの利点を失ってしまいます。

これはGraphQL特有のことではなく、よりカスタマイズ可能なAPIを選択することによってHTTPを介した任意のAPIに見つけることができます。エンドポイントベースのAPIでは、APIデザイナーがAPIの構築と取引を担当しています。GraphQLを選択することで、私たちは黙示的にカスタマイズ可能性の道を選んでいます。長期的に見て、キャッシュの無効化の問題がそれに見合った価値があることを願っています。「GraphQLはキャッシュ可能ではない」の代わりに、「高度にカスタマイズ可能なAPIはHTTPキャッシングからあまり利益を得られない」はどうでしょうか？

#### How Important is HTTP Caching to you?

HTTPキャッシングは、頻繁に変更されないデータに対して素晴らしいメカニズムです。特にゲートウェイキャッシュが関わる場合、複数のユーザー間で共有することができます。認証付きのWeb APIについては、HTTPキャッシングが実際にどれほど有用なのかについての永遠の議論があります。ここではその議論を解決するつもりはありませんが、それでも議論する価値はあります。

興味深い事実として、共有キャッシュは実際にはAuthorizationヘッダーを持つ任意のリクエストをキャッシュすべきではありません。APIが認証されている場合、「GraphQLがHTTPネットワーク/ゲートウェイ/共有キャッシュを壊す」という主張は単純に当てはまりません。プライベートキャッシュ（ブラウザキャッシュやクライアントサイドキャッシュなど）は、HTTPキャッシングを使用することで大いに利益を得ることができます。私たちが見た通り、GraphQLでこれが問題外ではないのは、クエリがどれだけ頻繁に無効化され、どれだけ少量のものが共有できるかという理由から、高度に最適化されたAPIやワンサイズフィットオールのAPIほど力強くはありません。

また覚えておくべきことは、多くのWeb APIは非常に長期間にわたって古いデータを持つことができず、これは新鮮さのヘッダーがあまり役に立たなくなることを意味します。

ETagやLast-Modifiedといったバリデータは、通常、サーバが必要なすべてのデータを取得し、ビジネスロジックを計算するために使用します。これは通常、大部分の作業であり、節約は主にシリアライゼーションと帯域幅上であり、データを転送する必要がないためです。帯域幅やシリアライゼーションが問題である場合、再度、GraphQLクエリ用のETagやLast-Modified生成を実装することを妨げるものは何もありません。GraphQLは確かに認証付きのAPIや頻繁に変更されるリアルタイムデータというものには非常に適しており、一方で公開APIとして長期にわたってデータを提供することに対してはあまり適していません。これがユースケースであり、APIが行う唯一のことである場合、HTTPをより意義深く使用するAPIアーキテクチャを検討することは良い選択かもしれません。

HTTPキャッシングはGraphQLに良い方法で恩恵をもたらすことができます。GraphQL over HTTPの仕様が欠けていることは事物を少し難しくします。GETメソッドを使用したミューテーションが実行される可能性があるという事実は、このような仕様によって解決できる例の1つです。しかし、GraphQLをキャッシュする他の方法はたくさんあります。それがクライアントレベルであったり、全レスポンスレベルであったり、個々のリゾルバレベルであったりします。実際には、Apolloのような特定のベンダーは、GraphQLに直接キャッシュセマンティクスを探索しています。本章では、現在最も多く使われているツールであり、長期的にはGraphQLセマンティクスを理解するためにより強力になり得るGraphQL特有のアプローチを主にカバーします。

#### Caching in Practice

ご覧の通り、GraphQLのキャッシングは繊細な問題です。高度に特定化されたパブリックエンドポイントベースのAPIと比較して効果が低いかもしれませんが、GraphQLでのキャッシングによる価値は多大であり、それは様々なレベルで得られます。

全クエリキャッシング
GraphQLに対するキャッシングのほとんどは、アプリケーションレベル、つまりサーバ内でより効果的です。最も一般的な問題は、GraphQLのクエリが一度に複数のエンティティにまたがることができるため、クエリがスキーマの一部をキャッシュすべきである部分と、同時にキャッシュすべきでない部分を使用することがあります。

例えば、Shopifyは非常に現実的なアプローチを取ってこの問題を解決しました。彼らはグローバルレベルでのキャッシングとGraphQLを解決しようとする代わりに、キャッシュ可能なクエリをキャッシュすることにしました。彼らの型の一部は製品、バリアント、画像などのストアフロント上の物事など、キャッシュ可能なオブジェクトを表します。彼らはヒット可能な型を定義するときに注釈をつけます。それは次のようになるでしょう：

```graphql
type Product @cacheable {
  name: String
}
```

クエリが実行されると、サーバはすべてのフィールドを見て、すべての型がキャッシュ可能であるかどうかを確認します。そうである場合、全体のクエリはキャッシュしても安全であり、クエリとユーザーコンテキストに基づいて生成されたキーの下にキャッシュされます。これは、多くのクエリがキャッシュ可能なストアフロント型にヒットしたため、素晴らしい進歩的な改善の例です。もちろん、ゴッチャは、一つの非キャッシュ可能なフィールドが追加されると、キャッシングの利点をすべて失うことです。

キャッシュキー
キャッシュキーの生成は常に重要であり、GraphQLではさらに重要です。GraphQLクエリの動的な性質は、クエリ内のスペースがキーに影響を及ぼし、元々同じクエリであったにも関わらずミスを引き起こす可能性があるということです。良いキャッシュキーは通常、少なくとも以下を含むべきです：
• ユーザー情報（認証されたAPIの場合）。
• 可能な限り正規化すべきクエリハッシュ。
• 変数ハッシュ（異なる変数を持つクエリが同じものとしてキャッシュされることは望ましくない）。
• 操作名
• キャッシュバスティング要素。
ユーザー情報部分は通常、user_idや何らかのクライアント識別子であり、一つのユーザーに所属するデータを他の全てのユーザーに提供するのを避けるためです。クエリハッシュは、クライアントが実行を求めているクエリ文字列の表現です。一般的には、空白、コメントなどから来るバリエーションを除去するために正規化すべきです。一部の人々はフィールドの順序を正規化すべきだとさえ言いますが、それは恐怖を感じるかもしれません。なぜなら、仕様は順序について何かを言っているからです。変数ハッシュは重要であり、すべての変数が常にクエリ文字列に含まれるわけではないからです。

また、操作名は忘れやすいですが非常に重要です。GraphQLでは、クライアントは一つのクエリ文字列内で複数の操作を定義することが許されています：

```graphql
query A {
  shop {
    name
} }
query B {
  shop {
    products {
      name
    }
  }
}
```

ほとんどのサーバが複数のクエリを実行しないものの、クライアントがoperation_nameを提供することを可能にしており、それが操作Aか操作Bを実行するべきかを教えてくれます。完全なレスポンスをキャッシュした場合、operation_nameをキャッシュせずに、この問題はすぐに壊れるでしょう。操作名としてBを提供するクライアントがクエリAの結果を得たり、その逆が起こったりする可能性があるからです。
最後に、「キャッシュバスティング要素」はあなた自身の実装に大いに依存するでしょう。前述のShopifyの例では、「shop_version」属性（ショップのストアフロントの現状を表す）が使用されています。これをキャッシュキーに含めることで、彼らはクエリが常に古くならないように保証しています。ある程度の古さを許容することができる場合は、代わりにTTL（Time-To-Live）アプローチを使用し、キャッシュキーに有効期限を設定することもできます。

データレイヤーキャッシング N+1問題について話す際に取り上げたバッチローダーを覚えていますか？彼らは効率的でないデータベースクエリを避けるだけでなく、重複したクエリをキャッシュするのにも役立ちます。次のクエリを考えてみましょう：

```graphql
query { 
  shop {
    owner { 
      shop {
        owner {
          shop {
            owner {
              name
            }
          }
        }
      }
    }
  }
}
```

キャッシングがない場合、パフォーマンスに関する章で見たように、私たちはshopとownerのフィールドにヒットするたびにデータベースクエリを行うことでしょう。幸いなことに、ほとんどのDataLoaderの実装はこれも面倒を見てくれます。彼らは、特定のエンティティに与えられたデータロードアクセスをバッチ処理だけでなくキャッシュします！
データキャッシングはおそらく最も効果的で、最も重要なレイヤであり、より高度なキャッシングに移る前に取り組むべきです。具体的なデータソースをバッチ化し、キャッシュすることは、高度に動的な実際のGraphQLクエリをキャッシュしようとするよりもはるかに簡単です。

リゾルバキャッシング
全レスポンスキャッシングは、GraphQLのクエリの動的な性質のために、正確に取得することは難しいかもしれません。そのため、私たちの中には個々のフィールドリゾルバーをキャッシュすることを選ぶ人もいます。私は個々のリゾルバーをキャッシュしようとする際には最善の判断を用いるように提案します。それがフィールド名および引数名に関しては簡単なキャッシュのように聞こえるかもしれませんが、私たちはしばしば、ほとんどの実装がリゾルバーでサポートしている強大なコンテキスト引数を忘れてしまいます。これは、リゾルバーの一般的なキャッシングソリューションを導入することは、そのコンテキストから生成された異なる値を考慮に入れる必要があるということを意味します。

この理由から、私は代わりにあなたが個々のリゾルバーのキャッシングを見てみるように提案します。つまり、あなたのシステムの他のロジックと同様にです。例えば、あなたのリゾルバーが高コストの呼び出しを行っている場合、それが問題を引き起こしているならそのフィールドのロジックを特にキャッシュすることを検討することを考えてみてください。

このセクションの導入で述べたように、GraphQLでもHTTPキャッシングが可能です。これの良い例はApolloサーバーです。これは、スキーマに基づいてHTTPキャッシングヘッダーを生成し、ランタイムでリゾルバーの特殊な関数を使用することができる強力なキャッシング実装を持っています。先述の通り、GraphQLでのキャッシングは少し効果が落ちるかもしれませんが、それは可能であり、実用的な方法で行うことができます。

#### Caching Summary

GraphQLのキャッシングは、どれだけクライアント駆動型であるかによって効果が少なくなるかもしれませんが、それが不可能だというわけではありません。永続化されたクエリのようなテクニックは、GraphQLと一緒にHTTPキャッシングを実際にかなり強力にします。もしあなたのAPIが主に静的＆公開データから成るなら、もっと効果的なAPIスタイルがあるかもしれません。しかし、異なるニーズを持つ複数のクライアントを支援し、対話型のデータを含む認証済みのAPIの場合、GraphQLは素晴らしい選択肢であり、キャッシングは実用的な方法で使用することができます。

### Compiled Queries

コンパイル済みクエリは、将来的にもっと見てみたいと思っているGraphQLの非常に興奮する領域です。詳細には触れませんが、コンパイル済みクエリは永続化されたクエリのアイデアをさらに進めます。標準的な永続化されたクエリは、登録されたクエリを他のクエリと同様に実行します（検証/分析をスキップする以外）。つまり、どのクエリが実行されるかは正確にわかっていても、GraphQLの実行エンジンのオーバーヘッドは依然として存在します。それを事前に最適化したらどうでしょうか？それこそがまさにコンパイル済みクエリが達成しようとしていることです。
現在、これらは主にアイデア段階ですが、すでにいくつかの例があります。GraphQLコンパイラーやエンジン、新しいクエリの実行方法は非常に興奮する領域であり、GraphQLのパフォーマンス面でのデメリットを解決する可能性があります。

### Summary

- GraphQLは、典型的なエンドポイントベースのAPIよりも最適化することが困難です。
- GraphQLの監視には、エンドポイントの応答時間を監視するのではなく、個々のフィールドやクエリを監視することが多いです。
- N+1問題は、遅延読み込みによって回避できます。
- GraphQLでもキャッシングが可能ですが、他のAPIスタイルと比較して、それほど強力ではないことが多いです。
- コンパイル済みクエリは、GraphQL APIのパフォーマンスを向上させるための有望な技術です。