## Security

GraphQLの世界ではセキュリティが注目されています。その一部は、「クライアントが必要なものだけを正確に問い合わせられる」と初めて聞いた人々が、クライアントがアクセスすべきでないデータにアクセスすることを懸念し始めるからです。実際、サーバーは公開したいユースケースだけを公開し、それ以上のものは公開しません。それでも、クライアントがサーバーをダウンさせたり、アクセスすべきでないものにアクセスしたりしないように、設定するべきことがいくつかあります。これらの多くは他のAPIスタイルと似ていますが、この章ではGraphQL特有のものをいくつか取り上げます。

### Rate Limiting

レート制限は、任意のWeb APIの非常に重要なセキュリティ機能です。APIがクライアントのユースケースに応答する必要がある一方で、APIクライアントが適切に動作する範囲内で制限を設定することも重要です。エンドポイントベースのAPIでは、これらの制限は通常、分あたりのリクエスト数などの形で表現されます。これは、サーバーにかかる負荷がしばしば一定期間に叩かれるエンドポイントの数に関連しているため、理にかなっています。問題は、これがGraphQLにはあまりうまく適用できないことです。なぜか理解するために、次のクエリを見てみましょう。

```graphql
query A {
  me {
    name
  } 
}
```

そして、この他のリクエスト:

```graphql
query {
# Loading the viewer costs 1
  viewer {
    # For 1 user, fetch 100 posts, costs 1
    posts(first: 100)  {
      edge {
        node {
          # For each post, load one author: 1x100, costs 1 
          author {
            name
          }
        }
      }
    }
  }
}
```

分ごとのリクエスト数やクエリ数でレート制限を強制するという単純なアプローチを使用すると、すぐに失敗します。最初のクエリを考えると、私たちの制限は公正だと思ったのですが、同じリクエスト数でも、2つ目のクエリはかなりコストがかかります。ここでの問題は、2つ目のクエリが1つ目よりもはるかに複雑で実行にコストがかかるため、これらのクエリについて同じ分あたりのクエリ数を許可することはできないということです。これがGraphQL APIが通常、クライアントのレート制限方法を完全に再考する必要がある理由です。では、GraphQL APIがクライアントを効果的にレート制限するためのいくつかの手法を見てみましょう。

#### Complexity Based Approach

GraphQL APIのレート制限に最も一般的な手法の1つは、複雑さに基づくアプローチを取ることです。基本的な考え方は次のようなものです：あるGraphQLクエリ文書が与えられた場合、そのコストを見積もることは可能でしょうか？前述の例で「クエリB」が100ポイント、「クエリA」が1ポイントの「コスト」を持つと言えるなら、時間に基づいたレート制限を行うための指標として、リクエスト数の代わりにこれを使用することができます。例えば、APIは分あたり1000ポイントまでしか実行できないように設定されているとします。その場合、クエリAは1分間に1000回実行することができますが、クエリBは10回しか実行できません。これにより、サーバー側でクエリを実行するのにどれだけコストがかかるかを正確に表現することができ、貴重なリソースを保護することができます。

#### Calculating Complexity

前述の例では、コストはかなりランダムな方法で計算しました。実際には、クエリの実行にかかるサーバ側のコストを正確に反映するコストを算出しようと努力します。それだけでなく、サーバーは通常、GraphQLクエリの実行前にそのコストまたは複雑さを計算したいと思います。これにより、APIはコストが非常に高いリクエストを遅すぎる前に拒否することができます。GraphQL Rubyのような一部のサーバー実装では、クエリ文書が実行される前に初めてパスを行うためのアナライザAPIがあります。これは、このロジックを実行するのに最適な場所です。JavaScriptの世界では、graphql-query-complexityのような類似のツールが存在します。そのようなAPIやライブラリを持っていない実装を使用している方々にとっては、ASTビジターや類似のツールを用いてクエリを解析し、複雑性スコアを計算するのが最良の選択です。
複雑さを計算する方法は多数あり、特定の実装は費用計算の方法に影響を与えるかもしれません。しかしながら、複雑さについて考え、オブジェクトをフィールドではなく、より具体的に考えるのは、しばしば非常に効果的なヒューリスティックです。スカラーフィールドは、すでにロード/デシリアライズされたオブジェクトから来るため、サーバーの計算コストは通常それほど高くありません。代わりに、サーバーがフェッチする必要があるオブジェクトタイプまたは「ノード」の数を計算します。

```graphql
query {
  viewer { # <== Loading the viewer costs 1
    name
    bio
    bestFriend { # <== The viewer's best friend also costs 1
      name # <== but we ignore name since it's a scalar 
    }
  }
}
```

次に直面する課題は、リストタイプが事態を複雑化することです。リストタイプを返す単一のフィールドは代わりにn個のオブジェクトをロードするかもしれず、これは予測するのが難しいです。幸いにも、GraphQL APIがページネーションされている場合、例えばRelayのConnection仕様を使用している場合、実際にはページネーションの引数を使用してコストを計算することができます。

```graphql
query {
# Loading the viewer costs 1
  viewer {
    # For 1 user, fetch 100 posts, costs 1
    posts(first: 100)  {
      edge {
        node {
          # For each post, load one author: 1x100, costs 1 
          author {
            name
          }
        }
      }
    }
  }
}
```

私たちのアプローチを考えると、このクエリは102ポイントのコストを持つことになります。これは、1つのviewerオブジェクト、100件の投稿の1ページ、そして100人の作者をロードしたからです。私たちのサーバーは効率的にユーザーから100件の投稿をロードすることができるため、投稿フィールドのコストを100に設定することができます。"乗数"効果は、投稿ごとに1人の著者をロードすることから生じます。これは通常、一般的なサーバー実装では計算が高価です。あなたのアプリケーションとアクセスパターンでデータフェッチがどれだけコストがかかるかに基づいて、これらの数字を調整することができます。

しかし、これでもページネーションされていないリストタイプについては問題が残っています。どのくらいのアイテムがロードされる可能性があるのか、どのようにして知ることができるのでしょうか？まず、このフィールドが本当にページャー化できないかどうかを確認してください。リストタイプがページネーションに適合しないケースは非常に稀です。もし不可能であれば、リストは小さく、それが将来的にも小さいままであると考える可能性があります。これは、それがあなたにとって意味のある平均的なコストを割り当てることができることを意味します。それが完全に正確である必要はありませんが、このフィールドがサーバー上でどのような負荷を発生させる可能性があるかを示すべきです。

レスポンスで返されたオブジェクトの数に基づいてレート制限を試みることもできます。例えば、コネクションが実際に20アイテムしか返さなかった場合、コストは20となりますが、99アイテムを返した場合、コストは99となります。これは間違いなくより正確ですが、レート制限アルゴリズムはもはや安定していません。クライアントアプリケーションが制限内であると考えていた場合でも、コレクションにいくつかのアイテムが追加されてコストが増え、レート制限が始まるという状況が発生します。これはクライアントにとって非常に困惑するものです。「静的」アプローチが大半の場合、より優れた選択肢であると思います。

#### Time Based Approach

正確な「複雑さのコスト」を計算することは難しい場合があります。代替的なアプローチとして、サーバー時間によるレート制限を採用することも考えられます。これは、サーバーの応答にかかった時間に基づいてコストを評価するため、本質的に真の「サーバーコスト」に近いです！このアプローチは、アプリケーションサーバーがリクエストを受け取り、レスポンスが送信されるまでの経過ミリ秒数を計算するミドルウェアを通じて行われることが多いです。私はこのアプローチが非常に好きです。しかし、先程の複雑さのアプローチと同じような問題があります：サーバーがクエリを実行するのにかかる時間は多くの要因に依存するため、例えばある日はクライアントが全く問題ないかもしれませんが、サーバーが少しだけ遅く応答する時間帯ではレート制限がかかる可能性があります。一部の人々はこれを特徴として見るかもしれません：サーバーが苦戦しているときにはより多くのレート制限を行う。
複雑さのアプローチと比べて、クライアントが理解するのは少し難しくなります。複雑さに基づくアプローチでは、クエリのコストがどれだけかを非常に簡単に表現することができます。あなたのアルゴリズムを共有したり、それを計算するツールを提供したりすれば、終わる前にそれを行うこともできます。時間を使って、クライアントは基本的にクエリを試してみて、それがどの程度時間がかかるかを見るか、または彼らのアプリケーションをデプロイする際に適応する必要があります。しかし、これらの両方の解決策は、単純にリクエスト数を数えるだけよりもはるかに優れています。

#### Exposing Rate Limits

クライアントにとって、彼らが制限内にいるのか、または続けた場合にレート制限がかかる可能性があるのかを知ることはしばしば難しいです。このため、多くのAPIプロバイダーは、クライアントがAPIの使用を適切に維持できるように支援するため、またはレート制限の状況をクライアントに伝えることを望んでいます。これを行う最も一般的な方法は、レスポンスヘッダーを通じて行われます。すべてのAPIレスポンスの一部として、我々は現在のレート制限の状態についての異なるヘッダーをクライアントに提供することができます。この例はGitHubのREST APIからのものです：

```json
Status: 200 OK
X-RateLimit-Limit: 5000
X-RateLimit-Remaining: 4999
X-RateLimit-Reset: 1372700873
```

RateLimit-Limitは、ユーザーがブロックされるまで（この場合は1時間）にリクエストできる合計数、RateLimit-Remainingは特定のユーザーがレート制限される前に残っている実際のリクエスト数、RateLimit-Resetは新しい期間が始まる時点を表すUnixタイムスタンプで、残りの数が元の上限（このケースでは5000）に戻ることを意味します。
私たちはGraphQLにおいても全く同じ戦略を適用することができ、ただし、LimitとRemainingの両方が複雑さのコストまたはサーバー時間の量を表すかもしれません。ヘッダー方式は非常にうまく機能しますが、GitHubのGraphQL APIでは、rateLimit GraphQLフィールドを含む追加のアプローチも採用しています。なかなかメタな感じがしますね。

```graphql
query {
  rateLimit {
    cost
    limit
    remaining
    resetAt
  }
  user(id: "123) {
    login
  }
}
```

rateLimitの下では、現在実行されているクエリのコストだけでなく、ヘッダーと同様にlimit、remaining、resetAtを問い合わせることができます。さらに興味深いことに、dryRun引数を渡すことで、クエリを実際に実行することなくこの情報を求めることができます。

```graphql
query {
# Dry run means the server will
# compute the complexity, but won't # fully execute the query
  rateLimit(dryRun: true) {
    cost
    limit
    remaining
    resetAt
  }
  user(id: "123) {
  login
  }
}
```

また、レスポンスの「extensions」はこの種の情報にも非常に適しています。たとえば、ShopifyのAPIでは、レート制限データを提供するためにextensionsキーを大いに活用しています。

```graphql
{
"data": {
    "shop": {
      "name": "ProductionReadyGraphQL"
  }
},
  "extensions": {
    "cost": {
      "requestedQueryCost": 1,
      "actualQueryCost": 1,
      "throttleStatus": {
        "maximumAvailable": 1000,
        "currentlyAvailable": 999,
        "restoreRate": 50
      }
    }
  }
}
```

これは、クライアントがこのようなクエリをどれだけたくさん作成できるかを推定したい場合に非常に役立ちます。
制限事項 クライアントにレート制限の詳細を公開することは非常に有用ですが、いくつかの注意点があることを理解する必要があります。主に：

クライアントが1時間/1分あたりの正確なリクエスト数を出すことでシステムを「ゲーム化」し、常に制限内に収まるようにすることが奨励されます。これは必ずしも悪いことではありませんが、将来的に変更するのが非常に困難になる可能性があります。
あなたが現在のシステムの状況を信頼性高く、一貫して正確に提供できると仮定します。リクエストが異なるデータセンターにルーティングされる場合や、同期的に取得できない情報に依存する場合など、これらの詳細を提供するのは難しいかもしれません。
これらの制限事項が問題となる可能性があると考える場合、適切な使用法を文書化し、クライアントにレート制限と上手く付き合う方法を教育し、奨励することが良いアプローチです。彼らのレート制限の状態について具体的な情報を与える代わりに、彼らがレート制限がかかった際に適切に対応することを期待します。クライアントにレート制限がかかったことを知らせる良いアプローチは、Retry-Afterヘッダーと共に429 TOO MANY REQUESTSステータスコードを使用することで、これによりクライアントは再度試すべき時間を知ることができます。

### Blocking Abusive Queries

GraphQLの力は、クライアントに多くの権限を与えることにあります。しかし、すべてのパワーをクライアントに与えるわけにはいきません。制限を設ける必要があります。最初に多くの人が考える一つのことは、クエリの深度を無限大に許可しないことです。何しろ、GraphQLはクライアントが非常に入れ子になったクエリを作成することを可能にします。

```graphql
query {
  product {
    variants {
      product {
        variants {
          product {
            # We can do that for a while
            variants {}
          }
        }
      }
    }
  }
}
```

これは実際にはカスタムバリデータとして実装することができます。例えば、GraphQL-JSには既に深度検証用のパッケージが用意されており、GraphQL Rubyはこれを標準で実装しています。
「再帰的」なクエリからGraphQLサーバーを保護するとよく聞くことがあります（これはまずGraphQLクエリ言語が許すものではありません。リーフノードは常に選択されなければならないからです）や、クエリの深度を制限するということです。しかし、クエリの深度は、悪意のあるクライアントがGraphQLサーバーを乱用する方法の一つだけで、実際には幅が同じくらい問題になることがあります。

```graphql
query {
  product1:
  product2: 
  product3: 
  product4: 
  product5: 
  # ...
}
```

これに対してどう防御すればよいのでしょうか？先ほど紹介したレート制限に対する複雑さのアプローチは、この問題をかなりよくカバーしています。最大深度や最大幅ではなく、最大複雑さを設定します。レート制限が時間経過によるサーバーの乱用を防ぐ一方で、非常に大きなクエリを送信することを許可しないために、クエリごとの最大複雑さを設定することも良い考えです。

複雑さ以外にも、クエリの制限に対する別のアプローチとしてノードの制限があります。多くの場合、これはクエリによって要求されるオブジェクトタイプのインスタンスがどれだけあるか、に効果的に変換されます。GitHubはクエリごとのノード制限と複雑さに基づくレート制限のアプローチを持っています。これらは、クライアントが無茶苦茶に大きなクエリを作成することを防ぎ、APIの使用が適切な範囲内に収まるようにしています。

最後に、クエリの複雑さをどのように計算するかに関わらず、回避方法があることが多いです。クエリと変数の合計バイトサイズに制限を設けることを強くお勧めします（たとえそれがかなり大きいものであっても）、これによって自分が存在するとは思っていなかった過度なクエリをブロックすることができます。例えば、巨大な引数のリストで特定のGraphQLサーバーをオーバーロードすることが可能です。これらをリスト引数の項目数に制限を設けることで防ぐことができますが、少なくとも合計サイズの制限はこれらのケースのいくつかをさらにブロックします。

### Timeouts

どんな手法を使って実行前に乱用的なクエリをブロックしたり、クライアントのレートを制限したりしても、単に複雑すぎるクエリを実行する可能性がまだあるかもしれません。どんなウェブサーバーでも、リクエスト時間には厳格なタイムアウトを設定し、クエリが長時間実行されることがないようにすべきです。タイムアウト値に完璧な量はありません、ただ一つあるべきであるということです。

GraphQLでは、タイムアウトは典型的なウェブAPIと比べて例外ではなく、むしろ機能に近くなるので興味深いです。計算時間が単に多すぎるクエリに対してはタイムアウトが予想されます。RESTのエンドポイントではタイムアウトの数が増えると通常は緊急事態となります。人々はページングされるかもしれません。しかし、GraphQLでは、サーバーが任意のクエリを受け入れる場合、タイムアウトに慣れる必要があるでしょう。

タイムアウトが設定されていると、ノードや複雑さの制限に何が起ころうとも、アクターが単一のクエリで取れる時間の上限があることを確信することができます。ここでの鍵は、要求をタイムアウトする前にクエリをブロックする最大複雑さと/またはノード制限を見つけることです。これは言うほど簡単ではありませんが、適切な監視、データ分析、そして試行錯誤により、正確な制限を見つけることができます。

### Authentication

認証はユーザーが誰であり、ログインしているかどうかを決定する行為です。これは認可と混同しないでください、これはユーザーがアクションを実行したり特定のリソースを見たりできるかどうかを決定する行為です。
GraphQLコミュニティでの認証に関する主要な問題は、それがGraphQLサーバー内で処理されるべきか、それともバンド外で処理されるべきかということです。実際的には、私たちのGraphQLスキーマがログインとログアウトスタイルのミューテーションを提供するべきか、それともユーザーがそれと対話する前に既にログインしていることを期待すべきかということを問っています。
私は認証の問題をGraphQLスキーマから除外し、クエリを実行する際にGraphQLのコンテキスト内にcurrentUserや他のセッション概念が存在することを単純に期待することを強く推奨します。リゾルバはHTTPヘッダーやトークンを意識してはいけません。このようにすると、スキーマを変更することなく、あるいは多数の認証スキームをサポートしたり交換したりできます。また、スキーマの操作がより簡単になり、より無状態になります。
GraphQLサーバー上に認証のミューテーションを持つことは、サーバーを状態保持のものにするか、フィールド毎に認証を処理することを必要とします。これは可能ですが、単にGraphQLクエリの実行時に常にトークンが存在することを期待する方が壊れやすいと感じます。
これにより、GraphQL側での認証チェックもより簡単になります。もちろん、欠点としては、クライアントがGraphQL以外の解決策を使って認証する必要があるかもしれません。これは私にとって大きな欠点には感じられませんでした。ログインミューテーションを使って単一のトークンを取得するだけの場合、GraphQLはシンプルなHTTPリクエストに対して多くの利点を提供しません。
認証ミドルウェアのような標準的な認証メカニズムを使うことをお勧めします、GraphQL内で自身の認証を試みるよりは。この方が頭痛の種がいくつか減るかもしれません。

### Authorization

APIのための認可は、私たちがGraphQL、REST、またはgRPCを使っているかどうかに関係なく、複雑な主題です。事実、認可は一般的に難しい問題です。

最適な認可方法を見つけるためには全体の本、そしておそらく科学的な研究が必要となるでしょう。事実、最良の方法はおそらく存在しないので、GraphQLでどのようにそれを行うべきかを推奨することは可能ではありません。
代わりに、GraphQLでは既存のアプリケーション内で既に持っている認可にできるだけ依存させたいです。私たちがGraphQLレベルで全ての認可ロジックを持つことを避けたい主な理由は、GraphQLはしばしばあなたのドメインロジックにアクセスする一つの可能な方法にすぎないからです。もし私たちがGraphQLレイヤーで全てを実装し始めると、これらのビジネスルールを他の場所すべてにコピーして維持する必要があり、エラーが発生しやすくなります。
一般的に、認可について話すとき、私たちは複数の概念を混同してしまいます。一方では、APIスコープのような認可があります。これは、クライアントがどのフィールドやタイプにアクセスすることを許されているか（OAuthなど）を指します。他方では、「管理者でない場合、問題を閉じることはできません」のような、私たちのドメインに近い認可シナリオがあります。通常、APIスコープはGraphQLレイヤーで実装されるのが理にかなっていますが、ドメインに関連するビジネスルールは可能な限りGraphQLロジックから離しておくべきです。
GraphQLレイヤーでいくつかの認可チェックを行う必要があることは間違いありません。この場合、考慮しなければならないいくつかの点があります。

#### Prioritize Object Authorization over Field Authorization

GraphQL APIの認可を強制する際によくある疑問は、タイプごとかフィールドごとかどちらで強制するべきかということです。
私の強い推奨は、認可ルールをフィールドではなくオブジェクトタイプに適用するアプローチから始めることです。その理由はいくつかあります。
まず、オブジェクトタイプは通常、APIスコープに非常によく変換されます。次に、特定のオブジェクトに対するシンプルなスカラーフィールドは通常、必要な権限の同じセットを共有します。
何よりも重要なのは、オブジェクトに到達する可能性のあるすべての方法を追跡するのは非常に難しいということです。もしフィールドレベルでのみ認可チェックを行うと、自身が思いつかなかったアクセスパターンが開かれる可能性があります。以下に、認可チェックがどこで行われるかを視覚化するのに役立つシンプルな@authorizationディレクティブを使った例を示します。

```graphql
type Query {
  adminThings: AdminOnlyType!
    @authorization(scopes: ["read:admin_only_types"])
}
```

この簡単なスキーマでは、read:admin_only_typesのスコープを持つクライアントのみがアクセスできます。なぜなら、そこに到達する唯一の方法はadminThingsフィールドを通じてであり、そのフィールドは私たちのフィールド認可によって十分に保護されているからです。しかし、スキーマがより複雑になり、異なるチームがスキーマの一部を追加していくと想像してみてください。

```graphql
type Query {
  adminThings: AdminOnlyType!
    @authorization(scopes: ["read:admin_only_types"])
  product: Product!
    @authorization(scopes: ["read:products"])
}
type Product {
  name: String
  settings: AdminOnlyType!
}
```

無意識のうちに、Productタイプのsettingsフィールドを通じてAdminOnlyTypeへの扉が開かれました。これに必要なのはread:productsのスコープだけです。これはまだ基本的な例ですが、あなたのスキーマが何千ものタイプに成長するとどうなるか考えてみてください。追跡やテストが非常に難しくなるでしょう。Nodeインターフェースとフィールドはこれを更に明示的にします。多くの場合、私たちはGlobal IDからほぼ全てにアクセスできます。これは私たちがフィールドが返すものではなく、タイプを保護する方向に進むことを示しています。
GraphQL-Rubyはデフォルトでこのアプローチを採用し、既存の認可フックを提供しています。

```ruby
class Types::Product < Types::BaseObject
  REQUIRED_SCOPE = "read:products"
  def self.authorized?(_object, context)
    context[:scopes].include?(REQUIRED_SCOPE)
end end
```

注：GraphQL rubyでは、親リゾルバーが返す実際のオブジェクト上でチェックを行うことも可能ですが、前述したように、これらのチェックの多くはGraphQLタイプ定義よりもビジネスレイヤーで行う方がよいでしょう。

GraphQL-ShieldもGraphQLに対する複雑な権限レイヤーを書くことを可能にするJavaScriptの人気ライブラリです。これにはたくさんの権限ルールを表現することができますので、APIレイヤーをシンプルに保つことができるならばそれを試みてください。フィールドごとのチェックアプローチには注意してください。全体として、私の推奨はGraphQLインターフェースの認可をシンプルに保つことです。これはおそらくセキュリティとメンテナンス性のための最善の方法です。ビジネスルールではなくAPI権限やAPIスコープに焦点を当て、最初はタイプごとにそれらを強制し、そこで細かく（フィールドごとの）権限が必要になるまで続けてください。

#### Leaking Existence

API認可の一般的な問題点は、「あなたが探しているものが存在しますが、アクセスできません」、「このものは存在しません（実際には存在しますが、私があなたに伝えるわけではありません）」という微妙な違いです。
多くの場合、誰かがアクセスしようとしたものに対するアクセス権がないということを伝えたくありません。例えば、グローバル識別子を使用してNodeインターフェースを実装するタイプをフェッチすることをクライアントに許可するnode(id: ID!)フィールドを考えてみましょう。もしクライアントが「あなたはこのオブジェクトにアクセスできません」というエラーを受け取った場合、このオブジェクトの存在が瞬時にクライアントに漏洩してしまいます。
この問題を回避するために、エラーを返す代わりに単純にnullを返します。これは、我々のタイプがnullableであるべきであることを意味します。そうでなければ、我々はレスポンスの大部分をnullにするリスクがあります。これは、フィールドを非nullableにする前に二度考える良い理由です。私たちはスキーマ設計について第2章で議論しました。

### Blocking Introspection

GraphQL APIのセキュリティ対策に関して最も一般的な懸念事項の一つは、サーバーからの自己調査能力を削除することです。これは一般的に私にとっては少し奇妙な感じがします。なぜなら、GraphQL APIが非常に使いやすい理由の一つだからです。しかし、もちろん、それはそのGraphQL APIを使用する背後の文脈によります。近日中に公開される機能を隠したい内部API、特にブラウザのような何か公開されているものを通じてアクセス可能な場合、秘密のものを漏洩させないために自己調査を制限する必要があります。内部APIでは、クエリホワイトリストを使用することもあります。これは、GraphQLサーバーが既知のクエリセットのみを実行できるようにするプロセスで、多くの場合は事前に登録されます。これはしばしば、他のクエリを実行するものから誰でもブロックするために、クライアントサイドのアプリケーションによって使用される個人APIで使用されます。自己調査は何よりもエンジニア/開発者のツールであり、エンドユーザーの物ではありません。これは、開発時には有効にすべきであるが、内部APIの場合、本番環境でオープンにする必要はない事を意味します。
しかし、公開GraphQL APIについては、自己調査に固有のセキュリティリスクは何もありません。なぜなら、スキーマは実際に私たちが露出させたいものだからです。このような場合に自己調査を制限すると、奇妙に「セキュリティバイオブスキュリティ」のように聞こえます。私たちは早い段階で取り上げた機能フラグのような、発見されるべきではないタイプやフィールドについては、スキーマの可視性を使用する方が良いと思います（これについては第2章で取り上げました）。これにより、特定のクライアントに対して我々のスキーマの特定の部分を隠すことができます。
これらの2つの事項が適切に実施されておらず、それが大量の労力を必要とする場合、よりシンプルな対策として自己調査を制限することができます。ただし、クライアントやツールにとって非常に重要な機能を制限している可能性があることを心に留めておいてください。

### Persisted Queries

持続的クエリはGraphQLの強みを利用しつつ、その痛み点を最小限に抑える非常に強力なコンセプトです。今までにおそらくかなりよく理解しているであろう、一般的なGraphQLクエリのフローを見てみましょう：

このシナリオでは、クライアントは典型的なGraphQLクエリをサーバーに送信し、サーバーはそのクエリを字句解析、パース、バリデーション、実行し、結果をクライアントに返します。仮にこのクライアントが本番環境にデプロイされたとしましょう。クライアントが送信するクエリ文字列が全く変わらないことが一つ気になります。実際には、毎回サーバーに全クエリを送信することは完全に無駄です！サーバーサイドの貴重なサイクルを浪費しています。なぜなら、我々は同じクエリ文字列を何度もパースし、バリデートしなければならないからです。持続的クエリはこの問題を解決しようと試みます。方法は以下の通りです：

持続的クエリでは、クライアントが全てのリクエストで完全なクエリ文書を送信する代わりに、クライアントはクエリが送信される前にサーバーにクエリを登録します。これらのクエリはデプロイプロセスの前や最中に登録されることもあります。他の場合では、クライアントからの最初のクエリが「登録」に使用されます。その見返りとして、持続的クエリをサポートできるGraphQLサーバーはそのクエリに対する識別子をクライアントに提供します。良い識別子の例としては、クエリハッシュ、クエリがアクセス可能なURL、または単純なIDが挙げられます。
クライアントが特定のクエリの識別子を持っている場合、クライアントはその識別子と必要な変数を送信し、この時点では全てのクエリ文書を通過させることなく、クエリを実行します。例えば、サーバーが特定のクエリの登録後にURLを返した場合、クライアントはこのURLを使用して毎回クエリ文書を送信する代わりにすることします。

これにはいくつかの素晴らしい利点があります。まず、クライアントはもはや全てのクエリ文字列を送信しないため、バンド幅を大幅に節約できます。しかし、それだけではありません。サーバーはクエリを最適化することができ、それらを事前にパースし、検証し、解析することができます。これらのものは特に大規模なクエリの場合、時間の経過と共に非常にコストがかかるようになるため、すべてのシリアスなGraphQL APIにとって持続したクエリは非常に良いアイデアです。
性能と帯域幅の改善の他に、これはAPIプロバイダーがGraphQL APIをセキュアにするのにも役立ちます。先ほど取り上げたクエリホワイトリストは、私たちのGraphQLサーバーに対して特定のクエリのみを実行させることを意味しています。持続的クエリでは、これがさらに簡単になり、APIプロバイダーは事前に登録されたクエリのみを実行させ、APIに対する他のすべてのクエリへのアクセスを基本的にブロックすることができます。
このように実装された持続的クエリの面白い点は、エンドポイントベースの固定クエリから逃れることを望んでいたものに非常に似ているということです。しかし、これを非常にパワフルにする小さな詳細があります。静的なクエリ/リソースを扱っていますが、これらのリソースはサーバーではなくクライアントによって生成されます。実際、私は持続的クエリを、必要とされるクライアントの数だけリソースを生成するための、ダイナミックなGraphQLエンジンを使用して、クライアントが動的に生成したリソースだと思っています。
Apolloには持続的クエリ周りの良いライブラリがあり、多くのサーバーサイドのライブラリにはクエリをキャッシュや永続化する機能があります。例えば、GraphQL Javaは事前にパースされたクエリをキャッシュする機能をサポートしており、GraphQL-Rubyはプロ版で操作ストアをサポートしています。

持続的クエリはすべての内部APIにとって必須であり、私はそれが最終的に公開APIにも有用となる可能性があると予想しています。

### Summary

• GraphQLのレート制限は、典型的なエンドポイントベースのAPIよりもより深く考える必要があります。
• 複雑さまたは時間ベースのアプローチがクライアントのレート制限にとって最良の選択です。
• 長時間実行されるクエリがサーバー時間を大量に消費するのを防ぐためにタイムアウトは必須です。
• クエリの深さは広告されているほど重要ではありません。複雑さとノード数だけで十分な場合が多いです。
• オブジェクトタイプを認証する方が、フィールドを認証するよりもシンプルで、エラーが少ないです。
• 内部APIの自己調査を無効にするのは良いアイデアですが、公開APIでは避けるべきです。
• 持続的クエリは非常に強力なコンセプトで、特に内部APIにとってそうです。